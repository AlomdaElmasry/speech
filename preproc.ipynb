{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './data/train/audio/' #download files from kaggle\n",
    "\n",
    "classes = ['yes', 'no', \n",
    "           'up', 'down', \n",
    "           'left', 'right', \n",
    "           'on', 'off', \n",
    "           'stop', 'go', \n",
    "           'silence', 'unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this cell to move the background noises folder out of the audio directory. We will create silence samples from these files after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mv data/train/audio/_background_noise_ data/train\n",
    "ls data/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split all the audio files from \\_background\\_noises\\_ folder in 1-sec chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_arr(arr):\n",
    "    \"\"\"\n",
    "    split an array into chunks of length 16000\n",
    "    Returns:\n",
    "        list of arrays\n",
    "    \"\"\"\n",
    "    return np.split(arr, np.arange(16000, len(arr), 16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_silence():\n",
    "    \"\"\"\n",
    "    reads wav files in background noises folder, \n",
    "    splits them and saves to silence folder in train_dir\n",
    "    \"\"\"\n",
    "    for file in os.listdir('data/train/_background_noise_/'):\n",
    "        if 'wav' in file:\n",
    "            sig, rate = librosa.load('data/train/_background_noise_/' + file, sr = 16000)        \n",
    "            sig_arr = split_arr(sig)\n",
    "            if not os.path.exists(train_dir+'silence/'):\n",
    "                os.makedirs(train_dir+'silence/')\n",
    "            for ind, arr in enumerate(sig_arr):\n",
    "                filename = 'frag%d' %ind + '_%s' %file # example: frag0_running_tap.wav\n",
    "                librosa.output.write_wav(train_dir+'silence/'+filename, arr, 16000)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_silence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probably a good idea to make more silence samples yourself. \n",
    "Perhaps just by recording walking or driving around without speaking.\n",
    "the silence class is underrepresented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three lists with file names. one for training set, one for validation set, one for all. Plus a dictionary with file counts per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(train_dir)\n",
    "# put folders in same order as in the classes list, used when making sets\n",
    "all_classes = [x for x in classes[:11]]\n",
    "for ind, cl in enumerate(folders):\n",
    "    if cl not in classes:\n",
    "        all_classes.append(cl)\n",
    "print(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train/validation_list.txt') as val_list:\n",
    "    validation_list = [row[0] for row in csv.reader(val_list)]\n",
    "assert len(validation_list) == 6798, 'file not loaded'\n",
    "\n",
    "\"\"\"\n",
    "#if you want to add the files in testing_list.txt to the validation list:\n",
    "\n",
    "with open('./data/train/testing_list.txt') as test_list:\n",
    "    testing_list = [row[0] for row in csv.reader(test_list)]\n",
    "assert len(testing_list) == 6835, 'file not loaded'\n",
    "\n",
    "#combine into validation set\n",
    "validation_list.extend(testing_list)\n",
    "\"\"\"\n",
    "#add silence files to validation_list\n",
    "for i, file in enumerate(os.listdir(train_dir + 'silence/')):\n",
    "    if i%10==0:\n",
    "        validation_list.append('silence/'+file)\n",
    "\n",
    "training_list = []\n",
    "all_files_list = []\n",
    "class_counts = {}\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(train_dir + folder)\n",
    "    for i, f in enumerate(files):\n",
    "        all_files_list.append(folder + '/' + f)\n",
    "        path = folder + '/' + f\n",
    "        if path not in validation_list:\n",
    "            training_list.append(folder + '/' + f)        \n",
    "        class_counts[folder] = i\n",
    "\n",
    "#remove filenames from validation_list that don't exist anymore (due to eda)\n",
    "validation_list = list(set(validation_list).intersection(all_files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(validation_list)+len(training_list)==len(all_files_list), 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check random file name\n",
    "print(training_list[345], 'size training set: ',len(training_list), 'size validation set: ', len(validation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot a wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, r = librosa.load(train_dir + 'yes/bfdb9801_nohash_0.wav', sr = 16000)\n",
    "print('min: ',np.min(x), \n",
    "      '\\nmax: ', np.max(x), \n",
    "      '\\nmean: ', np.mean(x),\n",
    "      '\\nmedian: ', np.median(x),\n",
    "      '\\nvariance: ', np.var(x),\n",
    "      '\\nlength: ', len(x))\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turn all wav files into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spec(file, file_dir = train_dir, flip = False, ps = False, st = 4):\n",
    "    \"\"\"\n",
    "    create a melspectrogram from the amplitude of the sound\n",
    "    \n",
    "    Args:\n",
    "        file (str): filename\n",
    "        file_dir (str): directory path\n",
    "        flip (bool): reverse time axis\n",
    "        ps (bool): pitch shift\n",
    "        st (int): half-note steps for pitch shift\n",
    "    Returns:\n",
    "        np.array with shape (122,85) (time, freq)\n",
    "    \"\"\"\n",
    "    sig, rate = librosa.load(file_dir + file, sr = 16000)\n",
    "    if len(sig) < 16000: # pad shorter than 1 sec audio with ramp to zero\n",
    "        sig = np.pad(sig, (0,16000-len(sig)), 'linear_ramp')\n",
    "    if ps:\n",
    "        sig = librosa.effects.pitch_shift(sig, rate, st)\n",
    "    D = librosa.amplitude_to_db(librosa.stft(sig[:16000], n_fft = 512, \n",
    "                                             hop_length = 128, \n",
    "                                             center = False), ref = np.max)\n",
    "    S = librosa.feature.melspectrogram(S=D, n_mels = 85).T\n",
    "    if flip:\n",
    "        S = np.flipud(S)\n",
    "    return S.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(make_spec('yes/bfdb9801_nohash_0.wav'), \n",
    "                         x_axis='mel', \n",
    "                         fmax=8000, \n",
    "                         y_axis='time', \n",
    "                         sr = 16000,\n",
    "                         hop_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_spec('yes/bfdb9801_nohash_0.wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets(file_list = training_list, unknowns = True):\n",
    "    X_array = np.zeros([len(file_list),122,85])\n",
    "    Y_array = np.zeros([len(file_list)])    \n",
    "    for ind, file in enumerate(file_list):\n",
    "        if ind%2000 == 0:\n",
    "            print(ind, file)\n",
    "        try:\n",
    "            X_array[ind] = make_spec(file)\n",
    "        except ValueError:\n",
    "            print(ind, file, ValueError)\n",
    "        if not unknowns:\n",
    "            Y_array[ind] = all_classes.index(file.rsplit('/')[0])\n",
    "        else:\n",
    "            if file.rsplit('/')[0] in classes:\n",
    "                Y_array[ind] = classes.index(file.rsplit('/')[0])\n",
    "            else: Y_array[ind] = 11\n",
    "    return X_array, Y_array\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = create_sets() # takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(X_train[6500], \n",
    "                         x_axis='mel', \n",
    "                         fmax=8000, \n",
    "                         y_axis='time', \n",
    "                         sr = 16000,\n",
    "                         hop_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape, 11 in Y_train, 12 in Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min: ',np.min(X_train), \n",
    "      '\\nmax: ', np.max(X_train), \n",
    "      '\\nmean: ', np.mean(X_train),\n",
    "      '\\nmedian: ', np.median(X_train),\n",
    "      '\\nvariance: ', np.var(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(X_train.flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the training sets, add channel dimension for keras,\n",
    "normalize around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/X_train.npy', np.expand_dims(X_train, -1)+1.3)\n",
    "np.save('data/Y_train.npy', Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = create_sets(file_list = validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_val.flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/X_val.npy', np.expand_dims(X_val, -1)+1.3)\n",
    "np.save('data/Y_val.npy', Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
